POD is designed to transform static PDFs into dynamic, summarized conversational podcasts. The core idea behind it is to make information consumption effortless and engaging, especially for users who prefer audio content over reading lengthy documents. By harnessing the power of artificial intelligence, POD automates the process of extracting key insights from PDFs, crafting natural-sounding scripts, and converting them into high-quality audio with distinct voices.

At the heart of POD lies a blend of technologies that ensure both efficiency and quality. The application leverages the Google Gemini API for summarization and script generation, distilling complex PDF content into concise, conversational dialogues. For audio production, it integrates the ElevenLabs API to deliver remarkably realistic text-to-speech output, featuring a two-voice format that mimics a natural podcast conversation. To handle the computationally intensive tasks without disrupting the user experience, POD employs asynchronous processing with Celery and Redis, queuing long-running jobs and enabling the backend to manage multiple concurrent requests based on preset concurrency levels. Security and scalability are also prioritized â€” PDF uploads are routed directly to AWS S3 using pre-signed URLs to minimize server load, while Redis-based rate limiting protects against abuse.

The technical architecture of POD is designed for robustness and seamless operation across the full stack. When a user hits the submit button, the FastAPI backend instantly creates a database record and dispatches a job ID to the Redis queue, allowing for an immediate response to the frontend while the heavy lifting happens in the background. A dedicated Celery worker, previously deployed on Fly.io (though currently paused due to financial constraints), picks up the job, retrieves the PDF from S3, processes it through the Gemini API for script generation, and makes multiple calls to ElevenLabs for voice-specific audio segments, which are then stitched together into a cohesive MP3 using the pydub library. The frontend, enhanced with shadcn/ui and daisyUI components, polls a secure API endpoint for status updates, while Supabase powers both data storage and a frontend-centric authentication system. Deployment-wise, the frontend runs on Vercel for optimal performance, and despite the backend pause, a live demo of inputs and outputs is available at https://podcast-pro-gilt.vercel.app/demo.
